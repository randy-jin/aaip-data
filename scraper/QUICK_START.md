# Quick Start - Automated Data Collection

## ğŸš€ What's Been Set Up

All 7 data sources now collect automatically **every hour**:

1. âœ… AAIP Processing & Draws (alberta.ca/aaip-processing-information)
2. âœ… AAIP News Updates (alberta.ca/aaip-updates) + Chinese translation
3. âœ… Express Entry Comparison
4. âœ… Alberta Economy Indicators
5. âœ… Labor Market Data
6. âœ… Job Bank Postings
7. âœ… Trend Analysis Engine

## ğŸ“ New Files Created

```
scraper/
â”œâ”€â”€ collect_all_data.py      â† Master orchestrator script
â”œâ”€â”€ setup_automation.sh       â† Interactive setup helper
â”œâ”€â”€ test_collectors.py        â† Test suite
â”œâ”€â”€ AUTOMATION_SETUP.md       â† Complete documentation
â”œâ”€â”€ AUTOMATION_SUMMARY.md     â† This summary
â””â”€â”€ QUICK_START.md            â† Quick reference

deployment/
â””â”€â”€ aaip-scraper.service      â† Updated to use orchestrator
```

## âš¡ Quick Commands

### Test Everything
```bash
cd scraper
python3 test_collectors.py     # Test imports
python3 collect_all_data.py    # Run all collectors
```

### Setup Automation
```bash
cd scraper
./setup_automation.sh          # Interactive setup
```

### On Production Server
```bash
# Deploy
cd /home/randy/deploy/aaip-data
git pull origin test
sudo cp deployment/aaip-scraper.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl restart aaip-scraper.timer

# Monitor
sudo systemctl status aaip-scraper.timer
sudo journalctl -u aaip-scraper.service -f

# Manual trigger
sudo systemctl start aaip-scraper.service
```

### Check Data
```bash
psql -d aaip_data_trend_dev_db -c \
  "SELECT * FROM scrape_log ORDER BY timestamp DESC LIMIT 10;"

psql -d aaip_data_trend_dev_db -c \
  "SELECT draw_date, stream_category, lowest_score 
   FROM aaip_draws ORDER BY draw_date DESC LIMIT 10;"

psql -d aaip_data_trend_dev_db -c \
  "SELECT published_date, title_en 
   FROM aaip_news ORDER BY published_date DESC LIMIT 10;"
```

## ğŸ“– Documentation

- **AUTOMATION_SETUP.md** - Complete setup guide (systemd + cron)
- **AUTOMATION_SUMMARY.md** - Full feature summary
- **CLAUDE.md** - Project documentation (updated)

## âœ¨ Key Features

- â° Runs every hour automatically
- ğŸ›¡ï¸ Critical failure handling
- ğŸ“Š Detailed logging
- â±ï¸ 5-minute timeout per collector
- ğŸŒ Bilingual support (EN + ZH)
- ğŸ“ˆ Comprehensive data coverage

---

**Everything is ready! Data collection will run automatically every hour.** ğŸ‰
